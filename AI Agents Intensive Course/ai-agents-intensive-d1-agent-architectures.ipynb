{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:12:16.684133Z","iopub.execute_input":"2025-11-11T08:12:16.684541Z","iopub.status.idle":"2025-11-11T08:12:16.689148Z","shell.execute_reply.started":"2025-11-11T08:12:16.684510Z","shell.execute_reply":"2025-11-11T08:12:16.688113Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"### Section 1\n\n## ‚öôÔ∏è Setup\n\n### Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:12:17.540746Z","iopub.execute_input":"2025-11-11T08:12:17.541087Z","iopub.status.idle":"2025-11-11T08:12:17.693925Z","shell.execute_reply.started":"2025-11-11T08:12:17.541060Z","shell.execute_reply":"2025-11-11T08:12:17.692923Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 1.2 Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:12:28.019587Z","iopub.execute_input":"2025-11-11T08:12:28.020421Z","iopub.status.idle":"2025-11-11T08:13:19.243993Z","shell.execute_reply.started":"2025-11-11T08:12:28.020386Z","shell.execute_reply":"2025-11-11T08:13:19.242997Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"---\n### Section 2\n\n## ü§î Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:51:07.943224Z","iopub.execute_input":"2025-11-11T08:51:07.943625Z","iopub.status.idle":"2025-11-11T08:51:07.950535Z","shell.execute_reply.started":"2025-11-11T08:51:07.943596Z","shell.execute_reply":"2025-11-11T08:51:07.949392Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:51:18.703566Z","iopub.execute_input":"2025-11-11T08:51:18.703918Z","iopub.status.idle":"2025-11-11T08:51:18.710614Z","shell.execute_reply.started":"2025-11-11T08:51:18.703891Z","shell.execute_reply":"2025-11-11T08:51:18.709487Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=\"gemini-2.5-flash-lite\",\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[\n        AgentTool(research_agent),\n        AgentTool(summarizer_agent)\n    ],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:51:39.851106Z","iopub.execute_input":"2025-11-11T08:51:39.852109Z","iopub.status.idle":"2025-11-11T08:51:39.858467Z","shell.execute_reply.started":"2025-11-11T08:51:39.852069Z","shell.execute_reply":"2025-11-11T08:51:39.857163Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"What are the latest advancements in quantum computing and what do they mean for AI?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:51:51.765620Z","iopub.execute_input":"2025-11-11T08:51:51.765921Z","iopub.status.idle":"2025-11-11T08:52:00.402079Z","shell.execute_reply.started":"2025-11-11T08:51:51.765898Z","shell.execute_reply":"2025-11-11T08:52:00.401136Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > Quantum AI is an emerging field that combines quantum computing with artificial intelligence. Key advancements in quantum computing, such as enhanced computational power through qubits and the ability to solve complex problems, are expected to revolutionize AI. This includes significantly speeding up AI model training, enabling breakthroughs in areas like drug discovery and materials science, and leading to more efficient data processing. Quantum computing also promises a more sustainable approach to AI. While still in its developmental stages, quantum error correction is a critical area of progress, and the field is poised for significant commercial growth in the coming decade, potentially leading to more sophisticated AI applications in natural language processing, cybersecurity, and autonomous systems.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n### Section 3\n## üö• Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:54:03.753853Z","iopub.execute_input":"2025-11-11T08:54:03.754159Z","iopub.status.idle":"2025-11-11T08:54:03.760621Z","shell.execute_reply.started":"2025-11-11T08:54:03.754139Z","shell.execute_reply":"2025-11-11T08:54:03.759427Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\", # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:54:03.935892Z","iopub.execute_input":"2025-11-11T08:54:03.936375Z","iopub.status.idle":"2025-11-11T08:54:03.941841Z","shell.execute_reply.started":"2025-11-11T08:54:03.936349Z","shell.execute_reply":"2025-11-11T08:54:03.940913Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\", # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:54:04.179161Z","iopub.execute_input":"2025-11-11T08:54:04.180010Z","iopub.status.idle":"2025-11-11T08:54:04.185191Z","shell.execute_reply.started":"2025-11-11T08:54:04.179973Z","shell.execute_reply":"2025-11-11T08:54:04.184324Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:54:15.646060Z","iopub.execute_input":"2025-11-11T08:54:15.646437Z","iopub.status.idle":"2025-11-11T08:54:15.651892Z","shell.execute_reply.started":"2025-11-11T08:54:15.646411Z","shell.execute_reply":"2025-11-11T08:54:15.650892Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a blog post about the benefits of multi-agent systems for software developers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:54:17.316849Z","iopub.execute_input":"2025-11-11T08:54:17.317141Z","iopub.status.idle":"2025-11-11T08:54:24.312743Z","shell.execute_reply.started":"2025-11-11T08:54:17.317120Z","shell.execute_reply":"2025-11-11T08:54:24.311825Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here is a blog outline about the benefits of multi-agent systems for software developers:\n\n### **Headline:** Unleash Your Code's Potential: How Multi-Agent Systems Are Revolutionizing Software Development\n\n### **Introduction Hook:**\nImagine software that can adapt, learn, and collaborate to solve complex problems with minimal human intervention. This isn't science fiction anymore. Multi-agent systems (MAS) are emerging as a powerful paradigm, offering developers a new toolkit to build more robust, intelligent, and efficient applications. But what exactly are they, and how can they benefit *you*?\n\n### **Main Sections:**\n\n**1. What is a Multi-Agent System? (The \"Who\" and \"What\")**\n    *   **Defining the Core Concept:** Briefly explain that a MAS is a system composed of multiple interacting intelligent agents, each capable of independent action and communication.\n    *   **Key Characteristics:** Highlight elements like autonomy, reactivity, proactivity, and social ability that define individual agents within the system.\n    *   **Beyond Simple Scripts:** Differentiate MAS from traditional monolithic or procedural software, emphasizing emergent behavior and distributed intelligence.\n\n**2. Enhanced Problem-Solving Capabilities (The \"Why it's Smart\")**\n    *   **Decomposition of Complexity:** Explain how MAS can break down large, intricate problems into smaller, manageable tasks assigned to specialized agents.\n    *   **Parallel Processing and Efficiency:** Discuss how agents can work concurrently, leading to faster execution times and improved resource utilization.\n    *   **Handling Dynamic and Uncertain Environments:** Illustrate how MAS can adapt to changing conditions and incomplete information by leveraging the collective intelligence of their agents.\n\n**3. Improved System Robustness and Resilience (The \"Why it's Reliable\")**\n    *   **Fault Tolerance:** Explain how the distributed nature of MAS means that the failure of a single agent doesn't necessarily bring down the entire system.\n    *   **Graceful Degradation:** Discuss how systems can continue to function, albeit with reduced capabilities, if some agents are unavailable.\n    *   **Self-Healing and Adaptation:** Touch upon how MAS can potentially detect and recover from failures or adapt their behavior to overcome unexpected challenges.\n\n**4. Flexibility and Scalability for the Future (The \"Why it's Future-Proof\")**\n    *   **Modular Design:** Emphasize how MAS promote a modular approach, making it easier to add, remove, or update individual agents without impacting the core system.\n    *   **Scalability:** Explain how MAS can be scaled by simply adding more agents to handle increased workloads or expanded functionalities.\n    *   **Evolving Architectures:** Discuss how MAS can be ideal for applications that need to evolve and adapt to new requirements over time.\n\n### **Concluding Thought:**\nAs software systems become increasingly complex and the demand for intelligent, adaptive solutions grows, multi-agent systems offer a compelling path forward for developers. By embracing this paradigm, you can build applications that are not only more powerful and efficient but also more resilient and future-ready. It's time to consider how intelligent agents can empower your next software project.\nWriterAgent > ## Unleash Your Code's Potential: How Multi-Agent Systems Are Revolutionizing Software Development\n\nImagine software that can adapt, learn, and collaborate to solve complex problems with minimal human intervention. This isn't science fiction anymore. Multi-agent systems (MAS) are emerging as a powerful paradigm, offering developers a new toolkit to build more robust, intelligent, and efficient applications. But what exactly are they, and how can they benefit *you*?\n\nAt its core, a MAS is a system composed of multiple interacting intelligent agents. These agents are autonomous, meaning they can act independently, and possess characteristics like reactivity (responding to their environment), proactivity (taking initiative), and social ability (communicating and coordinating with other agents). Unlike traditional monolithic code, MAS leverages distributed intelligence, leading to emergent behaviors and sophisticated problem-solving.\n\nOne of the most significant benefits is enhanced problem-solving. MAS excels at breaking down large, intricate problems into smaller, manageable tasks, each handled by a specialized agent. This decomposition, coupled with agents working concurrently, leads to faster execution times and improved efficiency. Furthermore, MAS can effectively handle dynamic and uncertain environments by adapting to changing conditions and incomplete information through collective intelligence.\n\nFor developers, MAS also means improved system robustness and resilience. The distributed nature inherently provides fault tolerance; the failure of one agent doesn't necessarily crash the entire system. This allows for graceful degradation, where the system can continue functioning with reduced capabilities if some agents are unavailable, and even facilitates self-healing mechanisms.\n\nFinally, MAS offers unparalleled flexibility and scalability for the future. Its modular design makes it easy to add, remove, or update individual agents without disrupting the core system. Scaling is as simple as adding more agents to handle increased workloads. This makes MAS ideal for applications that need to evolve and adapt to new requirements over time.\n\nAs software systems grow more complex, embracing multi-agent systems offers a compelling path to building powerful, efficient, resilient, and future-ready applications. It's time to explore how intelligent agents can elevate your next software project.\nEditorAgent > ## Unleash Your Code's Potential: How Multi-Agent Systems Are Revolutionizing Software Development\n\nImagine software that can adapt, learn, and collaborate to solve complex problems with minimal human intervention. This is no longer science fiction. Multi-agent systems (MAS) are emerging as a powerful paradigm, offering developers a new toolkit to build more robust, intelligent, and efficient applications. But what exactly are they, and how can they benefit *you*?\n\nAt its core, a MAS is a system composed of multiple interacting, intelligent agents. These agents are autonomous, meaning they can act independently, and possess characteristics like reactivity (responding to their environment), proactivity (taking initiative), and social ability (communicating and coordinating with other agents). Unlike traditional monolithic code, MAS leverages distributed intelligence, leading to emergent behaviors and sophisticated problem-solving capabilities.\n\nOne of the most significant benefits is **enhanced problem-solving**. MAS excels at breaking down large, intricate problems into smaller, manageable tasks, each handled by a specialized agent. This decomposition, coupled with agents working concurrently, leads to faster execution times and improved efficiency. Furthermore, MAS can effectively handle dynamic and uncertain environments by adapting to changing conditions and incomplete information through collective intelligence.\n\nFor developers, MAS also means **improved system robustness and resilience**. The distributed nature inherently provides fault tolerance; the failure of one agent doesn't necessarily crash the entire system. This allows for graceful degradation, where the system can continue functioning with reduced capabilities if some agents are unavailable, and even facilitates self-healing mechanisms.\n\nFinally, MAS offers unparalleled **flexibility and scalability for the future**. Its modular design makes it easy to add, remove, or update individual agents without disrupting the core system. Scaling is as simple as adding more agents to handle increased workloads. This makes MAS ideal for applications that need to evolve and adapt to new requirements over time.\n\nAs software systems grow increasingly complex, embracing multi-agent systems offers a compelling path to building powerful, efficient, resilient, and future-ready applications. It's time to explore how intelligent agents can elevate your next software project.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 4\n## üõ£Ô∏è Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:56:15.670497Z","iopub.execute_input":"2025-11-11T08:56:15.671761Z","iopub.status.idle":"2025-11-11T08:56:15.677180Z","shell.execute_reply.started":"2025-11-11T08:56:15.671725Z","shell.execute_reply":"2025-11-11T08:56:15.676303Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:56:16.905776Z","iopub.execute_input":"2025-11-11T08:56:16.906759Z","iopub.status.idle":"2025-11-11T08:56:16.912473Z","shell.execute_reply.started":"2025-11-11T08:56:16.906728Z","shell.execute_reply":"2025-11-11T08:56:16.911540Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:56:22.451684Z","iopub.execute_input":"2025-11-11T08:56:22.452116Z","iopub.status.idle":"2025-11-11T08:56:22.458137Z","shell.execute_reply.started":"2025-11-11T08:56:22.452089Z","shell.execute_reply":"2025-11-11T08:56:22.457084Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\", # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:56:31.372034Z","iopub.execute_input":"2025-11-11T08:56:31.372483Z","iopub.status.idle":"2025-11-11T08:56:31.378732Z","shell.execute_reply.started":"2025-11-11T08:56:31.372452Z","shell.execute_reply":"2025-11-11T08:56:31.377586Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:56:45.492847Z","iopub.execute_input":"2025-11-11T08:56:45.493174Z","iopub.status.idle":"2025-11-11T08:56:45.498668Z","shell.execute_reply.started":"2025-11-11T08:56:45.493150Z","shell.execute_reply":"2025-11-11T08:56:45.497522Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Run the daily executive briefing on Tech, Health, and Finance\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:56:48.787074Z","iopub.execute_input":"2025-11-11T08:56:48.788352Z","iopub.status.idle":"2025-11-11T08:56:55.133607Z","shell.execute_reply.started":"2025-11-11T08:56:48.788319Z","shell.execute_reply":"2025-11-11T08:56:55.132357Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nFinanceResearcher > **Tech:**\nArtificial intelligence (AI) continues its rapid evolution, with agentic AI and context engineering gaining prominence. These advancements require shifts in infrastructure orchestration, particularly involving GPUs, and sophisticated pipeline management. Cybersecurity remains critical due to increasing digital footprints and sophisticated threats like ransomware.\n\n**Health:**\nAI is a top investment priority, enhancing diagnostics, treatment, and operational efficiency. Personalized healthcare, driven by AI and data, is shifting focus to preventative measures. Investment in digital infrastructure, including EHRs and ERP platforms, is also key, with health systems increasingly using municipal bonds for strategic growth.\n\n**Finance:**\nThe industry is witnessing mega-mergers, particularly in India, aiming for global competitiveness. AI integration is central to risk analysis, compliance, and customer engagement, driving a move towards AI-driven autonomy. Evolving regulations and a focus on transparency and sustainability (ESG) are also key trends shaping the financial landscape.\nTechResearcher > **Key AI/ML Trends Shaping 2025**\n\n**1. Generative AI Advancements:** This trend focuses on AI's ability to create novel content, including text, images, video, and music. Leading companies like **OpenAI (ChatGPT)**, **Google (Gemini, Imagen)**, and **Anthropic (Claude)** are pushing the boundaries of generative models. The impact is a revolution in content creation, accelerating workflows, and personalizing user experiences across various industries.\n\n**2. Explainable AI (XAI) and Ethical AI:** As AI becomes more integrated into critical sectors like healthcare and finance, transparency and trustworthiness are paramount. XAI aims to make AI decision-making understandable, while ethical AI focuses on fairness and accountability. Companies are increasingly prioritizing these aspects to meet regulatory requirements and build user trust.\n\n**3. Multimodal AI:** This development involves AI systems capable of processing and integrating information from multiple data types simultaneously (e.g., text, images, audio). This enhances AI's understanding and capabilities, leading to more sophisticated applications. Major tech players like **Amazon (AWS Nova models)** are investing heavily in multimodal AI for diverse applications.\n\n**Companies Involved:** Key players include **Google**, **OpenAI**, **Microsoft**, **Amazon (AWS)**, **Anthropic**, **NVIDIA**, and **IBM**, alongside specialized firms like **Databricks** and **Dataiku**.\n\n**Potential Impact:** These trends promise significant impacts, including enhanced productivity through automation, more personalized user experiences, accelerated innovation in R&D (e.g., drug discovery), improved decision-making via advanced analytics, and the creation of new job roles, though also potential job displacement. The economic impact is projected to be substantial, with AI expected to contribute trillions to global GDP.\nHealthResearcher > Here's a brief on recent breakthroughs across Tech, Health, and Finance:\n\n**Technology:** AI continues its rapid advancement, with generative AI enhancing productivity and personalization. Agentic AI, capable of independent decision-making and complex task execution, is emerging as a major trend. Quantum computing and climate technology are also gaining traction.\n\n**Health:** Significant medical breakthroughs include CAR T-cell therapy showing promise for brain cancers. AI is revolutionizing diagnostics and treatment, with algorithms surpassing human accuracy in detecting diseases like cancer. Gene therapy is also advancing, offering new hope for genetic disorders.\n\n**Finance:** Fintech is being reshaped by embedded finance, where financial services are integrated into non-financial platforms, and the maturation of Decentralized Finance (DeFi). AI is increasingly powering personalization, fraud detection, and workflow automation. Regulatory changes are also influencing data sharing and open banking initiatives.\n\n**Estimated Timelines:** Many of these advancements are already being implemented or are expected to see widespread adoption within the next 1-3 years. For example, AI's impact is current and growing, while agentic AI and structural battery composites are projected for significant impact in the near future.\nAggregatorAgent > ## Executive Briefing: Intersecting Advancements in Tech, Health, and Finance\n\nArtificial Intelligence (AI) is the unifying force across technology, health, and finance, driving unprecedented innovation and transformation. In **technology**, generative AI is revolutionizing content creation and personalization, while emerging agentic AI promises more autonomous capabilities. Advancements in multimodal AI and the increasing demand for explainable and ethical AI underscore the growing sophistication and integration of these technologies, necessitating robust infrastructure, particularly GPU orchestration, and stringent cybersecurity measures.\n\nIn **health**, AI is a top investment priority, significantly enhancing diagnostics, treatment, and operational efficiency. AI-powered algorithms are achieving superior accuracy in disease detection, complementing breakthroughs in gene therapy and CAR T-cell treatments. The trend is shifting towards AI-driven personalized and preventative healthcare.\n\nThe **finance** sector is leveraging AI for risk analysis, compliance, and enhanced customer engagement, moving towards greater autonomy. Fintech innovations like embedded finance and the maturation of DeFi are reshaping the landscape, alongside evolving regulations focused on transparency, sustainability (ESG), and open banking.\n\nAcross all sectors, the rapid evolution and widespread adoption of AI, particularly within the next 1-3 years, signify a substantial economic impact and the creation of new opportunities, while also presenting challenges in job displacement and ethical considerations.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 5\n## ‚û∞ Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\", # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:57:57.008200Z","iopub.execute_input":"2025-11-11T08:57:57.008610Z","iopub.status.idle":"2025-11-11T08:57:57.015001Z","shell.execute_reply.started":"2025-11-11T08:57:57.008585Z","shell.execute_reply":"2025-11-11T08:57:57.013857Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\", # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:58:11.791345Z","iopub.execute_input":"2025-11-11T08:58:11.791712Z","iopub.status.idle":"2025-11-11T08:58:11.797442Z","shell.execute_reply.started":"2025-11-11T08:58:11.791687Z","shell.execute_reply":"2025-11-11T08:58:11.796472Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T08:58:27.339127Z","iopub.execute_input":"2025-11-11T08:58:27.339878Z","iopub.status.idle":"2025-11-11T08:58:27.345341Z","shell.execute_reply.started":"2025-11-11T08:58:27.339847Z","shell.execute_reply":"2025-11-11T08:58:27.344140Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    \n    output_key=\"current_story\", # It overwrites the story with the new, refined version.\n    tools=[FunctionTool(exit_loop)], # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T09:02:04.117336Z","iopub.execute_input":"2025-11-11T09:02:04.117660Z","iopub.status.idle":"2025-11-11T09:02:04.123987Z","shell.execute_reply.started":"2025-11-11T09:02:04.117638Z","shell.execute_reply":"2025-11-11T09:02:04.122963Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2, # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T09:02:05.221939Z","iopub.execute_input":"2025-11-11T09:02:05.222348Z","iopub.status.idle":"2025-11-11T09:02:05.229194Z","shell.execute_reply.started":"2025-11-11T09:02:05.222317Z","shell.execute_reply":"2025-11-11T09:02:05.228282Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T09:02:09.131827Z","iopub.execute_input":"2025-11-11T09:02:09.132127Z","iopub.status.idle":"2025-11-11T09:02:19.239414Z","shell.execute_reply.started":"2025-11-11T09:02:09.132106Z","shell.execute_reply":"2025-11-11T09:02:19.238321Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias had kept the Solitude Point light for thirty years. His world was the rhythmic sweep of the beam, the shriek of gulls, and the ceaseless murmur of the sea. One storm-tossed evening, a small, waterlogged chest washed ashore. Inside, nestled amongst barnacle-encrusted trinkets, was a map. It wasn't paper, but some strange, leathery material that pulsed with a soft, internal light. The symbols were unlike anything he'd ever seen ‚Äì swirling constellations and jagged lines that seemed to shift as he watched. He traced a glowing route that led not to any known landmass, but into a vast, uncharted expanse of ocean. A prickle of unease, and something akin to excitement, bloomed in his chest. The sea had always held secrets, but this felt different. This felt like an invitation.\nCriticAgent > - The pacing of the story is a bit too quick. While it sets up an intriguing premise, it rushes through Elias's discovery and his immediate reaction. Consider expanding on the storm, the discovery of the chest, and Elias's initial thoughts and feelings before he even opens it. This will build more suspense and allow the reader to connect with Elias's routine life being disrupted.\n- The description of the map, while evocative, could be more detailed. What kind of \"strange, leathery material\" is it? What are some of the specific symbols Elias sees, even if he doesn't understand them? Adding a few more concrete details will make the map feel more tangible and mysterious.\n- Elias's character is established as solitary and dedicated, but his internal reaction to the map feels a little generalized. While \"unease\" and \"excitement\" are good starting points, consider showing these emotions through his actions or more specific thoughts. For instance, does his hand tremble as he touches the map? Does he feel a sudden urge to abandon his post, or is it a quiet, deep-seated curiosity that begins to gnaw at him?\nRefinerAgent > The wind had been screaming at Solitude Point for three days, a banshee wail that Elias had long ago learned to distinguish from mere bluster. For thirty years, his life had been measured by the rhythmic sweep of the lighthouse beam, the abrasive cry of gulls, and the ceaseless, hypnotic murmur of the sea. It was a predictable, solitary existence, etched into the very bedrock of the isolated promontory he called home.\n\nOn the third night of the tempest, as Elias nursed a mug of lukewarm tea, the storm delivered a new kind of violence. A rogue wave, thicker and blacker than any he‚Äôd witnessed, slammed against the tower‚Äôs foundations, sending tremors through the ancient stone. When the dawn finally broke, painting a bruised sky in hues of purple and grey, Elias descended the winding stairs for his usual shoreline inspection.\n\nThe beach, usually a neat crescent of sand, was a chaotic jumble of kelp, driftwood, and the sea‚Äôs cast-off detritus. Then he saw it. Wedged between two jagged rocks, half-submerged in the churning surf, was a chest. It was small, no bigger than a sea trunk, and waterlogged, its dark wood swollen and warped. Barnacles clung to it like a shaggy, ancient beard. Elias‚Äôs heart gave an uncharacteristic lurch. He‚Äôd found flotsam before, of course, but there was something about this chest that felt‚Ä¶ deliberate.\n\nWith a grunt, he wrestled it free from the tide‚Äôs grasp. The wood was heavy, sodden, and smelled of brine and deep ocean. He carried it back to the lighthouse, the weight of it settling not just in his arms, but in his gut. He set it on the worn wooden table in his small living quarters, the rhythmic tick of his regulator clock the only sound save the dying roar of the sea outside. His gnarled fingers, accustomed to the rough textures of rope and brass, hesitated before touching the chest. It felt strangely smooth beneath the grit and salt, almost oily.\n\nHe worked the corroded latch with a seasoned pry bar. It groaned in protest before finally yielding with a sharp crack. The inside was lined with what looked like decaying velvet, now matted and dark. Nestled within were a few tarnished, unrecognizable trinkets ‚Äì a twisted piece of metal, a shard of what might have been glass, smooth and opaque. And then, beneath them, he found the map.\n\nIt wasn‚Äôt paper, or parchment, or any material Elias could readily identify. It was supple, like tanned hide, yet it possessed an unsettling resilience. And it glowed. A soft, internal luminescence, the color of moonlight on deep water, emanated from its surface. Elias‚Äôs breath hitched. He carefully lifted it, his fingers tingling as they brushed against the cool, pulsating surface.\n\nThe symbols were alien. Swirling patterns that mirrored nebulae in the night sky, but impossibly complex. Jagged, intersecting lines that didn‚Äôt map coastlines or currents he knew. As he tilted the map, the lines seemed to writhe, to shift, like living things. One particular route, a shimmering thread of light, pulsed brighter than the rest. It led away from any charted territory, away from the familiar arcs of his sweeping beam, and plunged into a vast, terrifyingly blank expanse of ocean.\n\nA shiver, not entirely of cold, traced its way down Elias‚Äôs spine. His hand, usually so steady when trimming the lamp or checking the barometer, trembled slightly. He felt a peculiar tightening in his chest, a sensation far removed from the dull ache of loneliness or the quiet satisfaction of a duty performed. It was a disquieting blend of profound unease and a sharp, almost desperate surge of curiosity. The sea had always been his world, a constant presence of predictable mysteries. But this map‚Ä¶ this map felt like a whisper from a place beyond his understanding, an invitation to a horizon he had never dared to imagine.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n### Section 6\n## Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}