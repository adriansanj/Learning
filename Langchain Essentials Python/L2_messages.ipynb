{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099d3a67",
   "metadata": {},
   "source": [
    "> **Disclaimer**  \n",
    "> This notebook uses content adapted from a course-provided notebook available at [github.com/langchain-ai/lca-langchainV1-essentials](https://github.com/langchain-ai/lca-langchainV1-essentials).  \n",
    "> All original credit belongs to the course authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a3c14-4a67-4d64-9378-0b9737e4a5f7",
   "metadata": {},
   "source": [
    "# ‚úâÔ∏è Messages\n",
    "  <img src=\"./assets/LC_Messages.png\" width=\"500\">\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c566d2-7844-4901-af65-4a6e58817716",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6ad0d-4efd-4066-9a8d-ca8bb0de94ef",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa9fb12-98e3-490d-9ae6-885054c8f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from bedrock import nova_pro as llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f27b5-a53a-4f24-9480-6af61823d4e6",
   "metadata": {},
   "source": [
    "## Humanüë®‚Äçüíª and AI ü§ñ Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ca38b8-7514-4e18-b141-86f77c684ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm, \n",
    "    system_prompt=\"You are a full-stack comedian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e517775-cdac-43ab-a40b-1a9e8deaa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "result = agent.invoke({\"messages\": [human_msg]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bcefc1-53d7-4723-a3dc-d87983be761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, I'm doing great! I've got all these jokes to share, and I'm feeling pretty byte-sized and punny today. But you know what they say: laughter is the best algorithm for a happy life! So, how about you? Ready for some humor optimization? üòÑüíª\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c37ca3-70f7-4f76-8108-94210ba7f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result[\"messages\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e186f7e-8818-4de4-bebd-4f73cebe5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Hello, how are you?\n",
      "\n",
      "ai: Well, I'm doing great! I've got all these jokes to share, and I'm feeling pretty byte-sized and punny today. But you know what they say: laughter is the best algorithm for a happy life! So, how about you? Ready for some humor optimization? üòÑüíª\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type}: {msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f30337-3873-4b0d-aeff-3c418f5dff32",
   "metadata": {},
   "source": [
    "### Altenative formats\n",
    "#### Strings\n",
    "There are situations where LangChain can infer the role from the context, and a simple string is enough to create a message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2450c1b-924a-422c-bac3-62b1f03dc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    system_prompt=\"You are a terse sports poet.\",  # This is a SystemMessage under the hood\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9a9f83-79d4-4abe-b1e3-45ef58d2f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diamond whispers, bat cracks,\n",
      "Grass whispers, glove smacks.\n",
      "Pitcher's dance, hitter's art,\n",
      "Innings flow, hearts depart.\n",
      "\n",
      "Home run dreams, strike-out fears,\n",
      "Catcher's mask, umpire's ears.\n",
      "Base paths run, stolen thrills,\n",
      "Victory cries, defeat chills.\n",
      "\n",
      "Sunlit fields, twilight glow,\n",
      "Game of life, ebb and flow.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Tell me about baseball\"})   # This is a HumanMessage under the hood\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1544d7-3590-42e9-a56b-0dfb34f28505",
   "metadata": {},
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b11e46-9c25-4828-9c6a-29a4594acdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash, breath, fire, gold.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"}}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00905cbe-b248-496f-898c-d223cd1fd0d7",
   "metadata": {},
   "source": [
    "There are multiple roles:\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sports poetry expert who completes haikus that have been started\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Feet don't fail me...\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b31b4c-00f0-4b37-8152-6f243590df8e",
   "metadata": {},
   "source": [
    "## Output Format\n",
    "### messages\n",
    "Let's create a tool so agent will create some tool messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27831c76-be27-4ee8-a24d-cc6d455f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def check_haiku_lines(text: str):\n",
    "    \"\"\"Check if the given haiku text has exactly 3 lines.\n",
    "\n",
    "    Returns None if it's correct, otherwise an error message.\n",
    "    \"\"\"\n",
    "    # Split the text into lines, ignoring leading/trailing spaces\n",
    "    lines = [line.strip() for line in text.strip().splitlines() if line.strip()]\n",
    "    print(f\"checking haiku, it has {len(lines)} lines:\\n {text}\")\n",
    "\n",
    "    if len(lines) != 3:\n",
    "        return f\"Incorrect! This haiku has {len(lines)} lines. A haiku must have exactly 3 lines.\"\n",
    "    return \"Correct, this haiku has 3 lines.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "879cad42-e41c-4d03-a118-585ff9dcfb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"You are a sports poet who only writes Haiku. You always check your work.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a70fbb-1d26-411c-aa87-6077bdf21868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking haiku, it has 3 lines:\n",
      " Nature's gentle touch,\n",
      "Whispers in the breeze,\n",
      "Peaceful moments found.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Please write me a poem\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b3f31f-7247-4d9c-811d-48b041d8eb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is your Haiku:\\n\\nNature's gentle touch,\\nWhispers in the breeze,\\nPeaceful moments found.\\n\\nThe tool has confirmed that it has exactly three lines.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "605faf3d-c76f-499d-abde-6fe0473eea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(result[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91779142-2d3a-4e9e-9827-69c538e8f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please write me a poem\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': '<thinking> To write a Haiku, I need to ensure it has exactly three lines. I will create a Haiku and then use the provided tool to check if it meets the requirement. </thinking>\\n\\n'}, {'type': 'tool_use', 'name': 'check_haiku_lines', 'input': {'text': \"Nature's gentle touch,\\nWhispers in the breeze,\\nPeaceful moments found.\"}, 'id': 'tooluse_P5v3aLaiSKW3h3vHDxt6_Q'}]\n",
      "Tool Calls:\n",
      "  check_haiku_lines (tooluse_P5v3aLaiSKW3h3vHDxt6_Q)\n",
      " Call ID: tooluse_P5v3aLaiSKW3h3vHDxt6_Q\n",
      "  Args:\n",
      "    text: Nature's gentle touch,\n",
      "Whispers in the breeze,\n",
      "Peaceful moments found.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_haiku_lines\n",
      "\n",
      "Correct, this haiku has 3 lines.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is your Haiku:\n",
      "\n",
      "Nature's gentle touch,\n",
      "Whispers in the breeze,\n",
      "Peaceful moments found.\n",
      "\n",
      "The tool has confirmed that it has exactly three lines.\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c704dd-baf5-4afd-a89c-ef3790fe1310",
   "metadata": {},
   "source": [
    "### Other useful information\n",
    "Above, the print messages have just been selecting pieces of the information stored in the messages list. Let's dig into all the information that is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1afcfa8-a706-403f-8c29-1f441d174908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Please write me a poem', additional_kwargs={}, response_metadata={}, id='77f6d8dd-b166-4a7c-99ff-9b5c6aeb1dab'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': '<thinking> To write a Haiku, I need to ensure it has exactly three lines. I will create a Haiku and then use the provided tool to check if it meets the requirement. </thinking>\\n\\n'}, {'type': 'tool_use', 'name': 'check_haiku_lines', 'input': {'text': \"Nature's gentle touch,\\nWhispers in the breeze,\\nPeaceful moments found.\"}, 'id': 'tooluse_P5v3aLaiSKW3h3vHDxt6_Q'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6a9a53de-87c1-4b27-a339-a681d947c79b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 18:15:08 GMT', 'content-type': 'application/json', 'content-length': '563', 'connection': 'keep-alive', 'x-amzn-requestid': '6a9a53de-87c1-4b27-a339-a681d947c79b'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1280]}, 'model_provider': 'bedrock_converse', 'model_name': 'eu.amazon.nova-pro-v1:0'}, id='lc_run--019b8a38-5a6f-7723-bb4b-41c161965c96-0', tool_calls=[{'name': 'check_haiku_lines', 'args': {'text': \"Nature's gentle touch,\\nWhispers in the breeze,\\nPeaceful moments found.\"}, 'id': 'tooluse_P5v3aLaiSKW3h3vHDxt6_Q', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 434, 'output_tokens': 80, 'total_tokens': 514, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  ToolMessage(content='Correct, this haiku has 3 lines.', name='check_haiku_lines', id='8dca3f60-891a-4212-b3c3-eeaba3e2ab1d', tool_call_id='tooluse_P5v3aLaiSKW3h3vHDxt6_Q'),\n",
       "  AIMessage(content=\"Here is your Haiku:\\n\\nNature's gentle touch,\\nWhispers in the breeze,\\nPeaceful moments found.\\n\\nThe tool has confirmed that it has exactly three lines.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'c5c973d5-a225-4e6b-9b92-8817b25c32a3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 18:15:09 GMT', 'content-type': 'application/json', 'content-length': '358', 'connection': 'keep-alive', 'x-amzn-requestid': 'c5c973d5-a225-4e6b-9b92-8817b25c32a3'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [758]}, 'model_provider': 'bedrock_converse', 'model_name': 'eu.amazon.nova-pro-v1:0'}, id='lc_run--019b8a38-5fd5-71a0-9815-81fd7e87a99c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 552, 'output_tokens': 34, 'total_tokens': 586, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0568f-41d7-48e3-b69e-f2b8123d941a",
   "metadata": {},
   "source": [
    "You can select just the last message, and you can see where the final message is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bacc660-7997-4da7-9d3e-eee4b8119601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here is your Haiku:\\n\\nNature's gentle touch,\\nWhispers in the breeze,\\nPeaceful moments found.\\n\\nThe tool has confirmed that it has exactly three lines.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'c5c973d5-a225-4e6b-9b92-8817b25c32a3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 18:15:09 GMT', 'content-type': 'application/json', 'content-length': '358', 'connection': 'keep-alive', 'x-amzn-requestid': 'c5c973d5-a225-4e6b-9b92-8817b25c32a3'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [758]}, 'model_provider': 'bedrock_converse', 'model_name': 'eu.amazon.nova-pro-v1:0'}, id='lc_run--019b8a38-5fd5-71a0-9815-81fd7e87a99c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 552, 'output_tokens': 34, 'total_tokens': 586, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7254b9e5-f6ac-432e-bf9a-05676f8e4b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 552,\n",
       " 'output_tokens': 34,\n",
       " 'total_tokens': 586,\n",
       " 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "523f453e-a425-4df0-88b0-a04e6e7612ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'c5c973d5-a225-4e6b-9b92-8817b25c32a3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 18:15:09 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '358',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'c5c973d5-a225-4e6b-9b92-8817b25c32a3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'stopReason': 'end_turn',\n",
       " 'metrics': {'latencyMs': [758]},\n",
       " 'model_provider': 'bedrock_converse',\n",
       " 'model_name': 'eu.amazon.nova-pro-v1:0'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5d505-a2db-4f64-9346-03af057b3be6",
   "metadata": {},
   "source": [
    "### Try it on your own!\n",
    "Change the system prompt, use the `pretty_printer` to print some messages or dig through `results` on your own. Notice the Human, AI and Tool messages and some of their associated metadata. Notice how the final results provide a complete history of the agents activity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f921687f-005c-4727-b041-18bafbfaf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"Your SYSTEM prompt here\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5e27be2-6bf9-4c0e-b466-8f9e483bfe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please write me a poem\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': '<thinking> To write a Haiku, I need to ensure it has exactly three lines. I will create a Haiku and then use the provided tool to check if it meets the requirement. </thinking>\\n\\n'}, {'type': 'tool_use', 'name': 'check_haiku_lines', 'input': {'text': \"Nature's gentle touch,\\nWhispers in the breeze,\\nPeaceful moments found.\"}, 'id': 'tooluse_P5v3aLaiSKW3h3vHDxt6_Q'}]\n",
      "Tool Calls:\n",
      "  check_haiku_lines (tooluse_P5v3aLaiSKW3h3vHDxt6_Q)\n",
      " Call ID: tooluse_P5v3aLaiSKW3h3vHDxt6_Q\n",
      "  Args:\n",
      "    text: Nature's gentle touch,\n",
      "Whispers in the breeze,\n",
      "Peaceful moments found.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_haiku_lines\n",
      "\n",
      "Correct, this haiku has 3 lines.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is your Haiku:\n",
      "\n",
      "Nature's gentle touch,\n",
      "Whispers in the breeze,\n",
      "Peaceful moments found.\n",
      "\n",
      "The tool has confirmed that it has exactly three lines.\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909edca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
