{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5becb32",
   "metadata": {},
   "source": [
    "> **Disclaimer**  \n",
    "> This notebook uses content adapted from a course-provided notebook available at [github.com/langchain-ai/lca-langchainV1-essentials](https://github.com/langchain-ai/lca-langchainV1-essentials).  \n",
    "> All original credit belongs to the course authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from bedrock import nova_pro as llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Streaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you:\n",
      "\n",
      "Why did the full-stack developer go broke?\n",
      "\n",
      "Because he used up all his cache! ðŸ’°ðŸ’»\n",
      "\n",
      "Hope that made you laugh! Remember, laughter is the best UI/UX. ðŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values\n",
    "You have seen this streaming mode in our examples so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Alright, here's a dad joke for you:\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field! ðŸŒ¾ðŸ˜„\n",
      "\n",
      "Hope that brought a smile to your face!\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages\n",
    "Messages stream data token by token - the lowest latency possible. This is perfect for interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a family-friendly poem called \"The Adventures of Sunny the Sun\":\n",
      "\n",
      "---\n",
      "\n",
      "In the sky so high and wide,\n",
      "Lives Sunny the Sun with a gleaming stride.\n",
      "He wakes up each morn with a cheerful grin,\n",
      "Ready to start his day, let the fun begin!\n",
      "\n",
      "With a stretch and a yawn, he peeks out the door,\n",
      "\"Good morning, world!\" he says, and much more.\n",
      "He sends down his rays, warm and bright,\n",
      "To greet every corner, bathing in light.\n",
      "\n",
      "Sunny waves to the mountains, tall and grand,\n",
      "And the oceans below, a shimmering strand.\n",
      "He tickles the trees with his golden beams,\n",
      "Waking up flowers from their sleepy dreams.\n",
      "\n",
      "The birds chirp hello as they take to the sky,\n",
      "Sunny winks at them, \"Don't be in a hurry, fly!\"\n",
      "He paints the clouds in shades of white,\n",
      "Creating fluffy castles, a delightful sight.\n",
      "\n",
      "When the day grows long and the evening nears,\n",
      "Sunny slows his dance, with no fears.\n",
      "He dons a red and orange cloak so fine,\n",
      "As he starts his descent, a beautiful decline.\n",
      "\n",
      "He whispers goodnight to the moon up high,\n",
      "\"Take over the watch, light up the sky.\"\n",
      "With a final warm hug to the Earth below,\n",
      "Sunny rests for the night, ready for tomorrow's glow.\n",
      "\n",
      "So whenever you gaze at the sky above,\n",
      "Remember Sunny the Sun and his endless love.\n",
      "He brings light to our days, with a smile so bright,\n",
      "A shining example, day and night.\n",
      "\n",
      "---"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):  \n",
    "    if token.content:\n",
    "        print(token.content[-1].get(\"text\", \"\"), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A `get_stream_writer` writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fdb4da70-9542-4495-ab1c-6342e0fea5fc')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fdb4da70-9542-4495-ab1c-6342e0fea5fc'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has asked for the weather in SF, which is commonly known as San Francisco. I need to use the 'get_weather' tool to fetch the current weather information for San Francisco. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'get_weather', 'input': {'city': 'San Francisco'}, 'id': 'tooluse_BqjnTUrTRdCRpod0xlikjw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '3aabfe6b-0de9-4576-8ed3-abb5140676c8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 19:14:27 GMT', 'content-type': 'application/json', 'content-length': '523', 'connection': 'keep-alive', 'x-amzn-requestid': '3aabfe6b-0de9-4576-8ed3-abb5140676c8'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1170]}, 'model_provider': 'bedrock_converse', 'model_name': 'eu.amazon.nova-pro-v1:0'}, id='lc_run--019b8a6e-a8c8-7701-9865-9bc457e5ccca-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'tooluse_BqjnTUrTRdCRpod0xlikjw', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 398, 'output_tokens': 62, 'total_tokens': 460, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]})\n",
      "('custom', 'Looking up data for city: San Francisco')\n",
      "('custom', 'Acquired data for city: San Francisco')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fdb4da70-9542-4495-ab1c-6342e0fea5fc'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has asked for the weather in SF, which is commonly known as San Francisco. I need to use the 'get_weather' tool to fetch the current weather information for San Francisco. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'get_weather', 'input': {'city': 'San Francisco'}, 'id': 'tooluse_BqjnTUrTRdCRpod0xlikjw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '3aabfe6b-0de9-4576-8ed3-abb5140676c8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 19:14:27 GMT', 'content-type': 'application/json', 'content-length': '523', 'connection': 'keep-alive', 'x-amzn-requestid': '3aabfe6b-0de9-4576-8ed3-abb5140676c8'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1170]}, 'model_provider': 'bedrock_converse', 'model_name': 'eu.amazon.nova-pro-v1:0'}, id='lc_run--019b8a6e-a8c8-7701-9865-9bc457e5ccca-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'tooluse_BqjnTUrTRdCRpod0xlikjw', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 398, 'output_tokens': 62, 'total_tokens': 460, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='18a21c11-9145-4c9a-9526-9ae51b7d5dcd', tool_call_id='tooluse_BqjnTUrTRdCRpod0xlikjw')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fdb4da70-9542-4495-ab1c-6342e0fea5fc'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has asked for the weather in SF, which is commonly known as San Francisco. I need to use the 'get_weather' tool to fetch the current weather information for San Francisco. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'get_weather', 'input': {'city': 'San Francisco'}, 'id': 'tooluse_BqjnTUrTRdCRpod0xlikjw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '3aabfe6b-0de9-4576-8ed3-abb5140676c8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 19:14:27 GMT', 'content-type': 'application/json', 'content-length': '523', 'connection': 'keep-alive', 'x-amzn-requestid': '3aabfe6b-0de9-4576-8ed3-abb5140676c8'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1170]}, 'model_provider': 'bedrock_converse', 'model_name': 'eu.amazon.nova-pro-v1:0'}, id='lc_run--019b8a6e-a8c8-7701-9865-9bc457e5ccca-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'tooluse_BqjnTUrTRdCRpod0xlikjw', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 398, 'output_tokens': 62, 'total_tokens': 460, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='18a21c11-9145-4c9a-9526-9ae51b7d5dcd', tool_call_id='tooluse_BqjnTUrTRdCRpod0xlikjw'), AIMessage(content=\"<thinking> The tool has returned a result indicating that it's always sunny in San Francisco. This is likely a humorous or generic response rather than an accurate weather report. I should inform the user that the tool provided a non-specific response and suggest they check a reliable weather service for accurate information. </thinking>\\n\\nThe tool provided a generic response stating that it's always sunny in San Francisco. For accurate and up-to-date weather information, please check a reliable weather service.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '969bb1af-9833-4001-bce6-a0ff43ec0ae8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 04 Jan 2026 19:14:29 GMT', 'content-type': 'application/json', 'content-length': '723', 'connection': 'keep-alive', 'x-amzn-requestid': '969bb1af-9833-4001-bce6-a0ff43ec0ae8'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1452]}, 'model_provider': 'bedrock_converse', 'model_name': 'eu.amazon.nova-pro-v1:0'}, id='lc_run--019b8a6e-adad-71f2-b036-bccc169ad739-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 495, 'output_tokens': 99, 'total_tokens': 594, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer #Used to stream tool data\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: San Francisco')\n",
      "('custom', 'Acquired data for city: San Francisco')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: San Francisco\n",
      "Acquired data for city: San Francisco\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
